{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Paris' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run-c4dfe3b1-ec54-4b06-8eb2-5da7c314434c-0' usage_metadata={'input_tokens': 7, 'output_tokens': 2, 'total_tokens': 9, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoConfig, pipeline, BitsAndBytesConfig\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "import os\n",
    "import torch\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\".\")\n",
    "from configs.config import Load_config\n",
    "CONFIG = Load_config()\n",
    "\n",
    "class Model_loader:\n",
    "   def load_gemini():\n",
    "      return ChatGoogleGenerativeAI(\n",
    "         model= CONFIG.GOOGLE_MODEL,\n",
    "         google_api_key= CONFIG.GOOGLE_API_KEY\n",
    "   )\n",
    "\n",
    "llm = Model_loader.load_gemini()\n",
    "response = llm.invoke(\"What is the capital of France?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The coder toiled, both late and long,\\nWith datasets vast, a tangled throng.\\nAPIs whispered, a cryptic plea,\\n\"Connect us all, set knowledge free!\"\\n\\nThen through the screen, a light did gleam,\\nLangChain arose, a waking dream.\\nA framework strong, a binding thread,\\nTo weave the words, the thoughts unsaid.\\n\\nFrom LLMs grand, like Bard so bold,\\nTo vector stores, a wealth untold,\\nLangChain reached out, a guiding hand,\\nConnecting pieces, across the land.\\n\\nIt chained the prompts, in elegant flow,\\nFrom question asked, to answer\\'s glow.\\nIt managed memory, with skillful art,\\nAnd held the context, close to its heart.\\n\\nThe agents danced, a vibrant crew,\\nWith tools and tasks, both old and new.\\nThey searched and scraped, they planned and wrote,\\nA symphony of code, afloat.\\n\\nNo longer bound by rigid walls,\\nThe coder\\'s spirit freely calls.\\nWith chains of logic, forged with care,\\nLangChain empowers, beyond compare.\\n\\nSo raise a glass, to this new age,\\nWhere language models grace the stage.\\nAnd thank the chain, so strong and true,\\nThat binds the knowledge, just for you.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run-7eaa8ade-c57c-409f-a74e-5585208405b6-0' usage_metadata={'input_tokens': 7, 'output_tokens': 271, 'total_tokens': 278, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Truyền trực tiếp API key\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    google_api_key=\"AIzaSyAOiSV0fCbCyXsLcVqYXTCZnWEEIImqXYc\"\n",
    ")\n",
    "\n",
    "# Gọi mô hình\n",
    "response = llm.invoke(\"Write me a ballad about LangChain\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
